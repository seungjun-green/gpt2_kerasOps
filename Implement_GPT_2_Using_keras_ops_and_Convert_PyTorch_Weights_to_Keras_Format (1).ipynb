{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c59a8862fa6548059e2c139e1e51d9e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17d7f7d8b0014d71b61da0daccb20c58",
              "IPY_MODEL_9e8dfbe6dc9a4faa92365cbf385b93b4",
              "IPY_MODEL_c6701e6811064783a71c0a986efe7ccf"
            ],
            "layout": "IPY_MODEL_7ef994692f004aca828c9affaedaa582"
          }
        },
        "17d7f7d8b0014d71b61da0daccb20c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eb13398c0f64ce58c909db8f8063a2d",
            "placeholder": "​",
            "style": "IPY_MODEL_14847a14e58346f4a00824028b6d07b4",
            "value": "config.json: 100%"
          }
        },
        "9e8dfbe6dc9a4faa92365cbf385b93b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9783fc3938245e5b36e04e0df58f147",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_673c1e87b0444f7dbe9272f81870a92d",
            "value": 665
          }
        },
        "c6701e6811064783a71c0a986efe7ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccc142ac021d40ccb7ed21314cbbde37",
            "placeholder": "​",
            "style": "IPY_MODEL_ddc4e6b86a654920a6359c9065ec40eb",
            "value": " 665/665 [00:00&lt;00:00, 46.4kB/s]"
          }
        },
        "7ef994692f004aca828c9affaedaa582": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eb13398c0f64ce58c909db8f8063a2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14847a14e58346f4a00824028b6d07b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9783fc3938245e5b36e04e0df58f147": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "673c1e87b0444f7dbe9272f81870a92d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccc142ac021d40ccb7ed21314cbbde37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddc4e6b86a654920a6359c9065ec40eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49934abd9e314698a5939a4bccfe9881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_083d026533bd406a849331aafd6953b3",
              "IPY_MODEL_10cda91616b14ee18ea29ac1d172027a",
              "IPY_MODEL_298828cbfbbf44f4b21af431a8c5155e"
            ],
            "layout": "IPY_MODEL_b166e859c8534a40a37f0486e0ba6b70"
          }
        },
        "083d026533bd406a849331aafd6953b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ec702dba4fc41b2b1f2b5da5148aa32",
            "placeholder": "​",
            "style": "IPY_MODEL_26bb2ab14ac34d8e8a6fe81a1c949d14",
            "value": "model.safetensors: 100%"
          }
        },
        "10cda91616b14ee18ea29ac1d172027a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a711f6ed1b5b42a99b244da03e0cd531",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb52338772604c1d8bda2eb37f03b127",
            "value": 548105171
          }
        },
        "298828cbfbbf44f4b21af431a8c5155e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b57a2f3a68c54023b0a1e4c8d67781e1",
            "placeholder": "​",
            "style": "IPY_MODEL_21a47d11fbd84624bef7fefa66fc85e0",
            "value": " 548M/548M [00:05&lt;00:00, 48.6MB/s]"
          }
        },
        "b166e859c8534a40a37f0486e0ba6b70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ec702dba4fc41b2b1f2b5da5148aa32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26bb2ab14ac34d8e8a6fe81a1c949d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a711f6ed1b5b42a99b244da03e0cd531": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb52338772604c1d8bda2eb37f03b127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b57a2f3a68c54023b0a1e4c8d67781e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21a47d11fbd84624bef7fefa66fc85e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implement GPT-2 Using keras.ops and Convert PyTorch Weights to Keras Format"
      ],
      "metadata": {
        "id": "XazpWMwEz7h1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "mYXk4C-m0J8N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K8I0tl_DDVvd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras import backend as K\n",
        "import keras.ops as ops\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Model, GPT2Tokenizer\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement GPT2 using Keras.ops"
      ],
      "metadata": {
        "id": "Nfi682DsE2xN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Layer**"
      ],
      "metadata": {
        "id": "3_04a7naTE5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDense(keras.layers.Layer):\n",
        "  def __init__(self, units, activation=None, name=None, **kwargs):\n",
        "    super().__init__(name=name, **kwargs)\n",
        "    self.units = units\n",
        "    self.activation = keras.activations.get(activation)\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    input_dim = input_shape[-1]\n",
        "\n",
        "    self.kernel = self.add_weight(\n",
        "        shape=(input_dim, self.units),\n",
        "        initializer=\"glorot_uniform\",\n",
        "        trainable=True,\n",
        "        name=\"kernel\"\n",
        "    )\n",
        "\n",
        "    self.bias = self.add_weight(\n",
        "        shape=(self.units,),\n",
        "        initializer=\"zeros\",\n",
        "        trainable=True,\n",
        "        name=\"bias\"\n",
        "    )\n",
        "\n",
        "    self.built = True\n",
        "\n",
        "  def call(self, inputs):\n",
        "    outputs = ops.matmul(inputs, self.kernel)\n",
        "    outputs = ops.add(outputs, self.bias)\n",
        "\n",
        "    if self.activation is not None:\n",
        "      outputs = self.activation(outputs)\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "_IGBViYfEi2e"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Embedding Layer**"
      ],
      "metadata": {
        "id": "dUeTvGqOTKnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomEmbedding(keras.layers.Layer):\n",
        "  def __init__(self, input_dim, output_dim, embeddings_initializer=\"uniform\", mask_zero=False, name=None, **kwargs):\n",
        "    super().__init__(name=name, **kwargs)\n",
        "    self.input_dim = input_dim\n",
        "    self.output_dim = output_dim\n",
        "    self.embeddings_initializer = keras.initializers.get(embeddings_initializer)\n",
        "    self.mask_zero = mask_zero\n",
        "    self.supports_masking = self.mask_zero\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    # here input_dim is vocab size and output dim is embedding dim\n",
        "    self.embeddings = self.add_weight(\n",
        "        shape=(self.input_dim, self.output_dim),\n",
        "        initializer=self.embeddings_initializer,\n",
        "        name=\"embeddings\"\n",
        "    )\n",
        "    self.built=True\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # embeddings has shape of (vocab_szie, embedding_dim).\n",
        "    # u can think of each row represent a certain word.\n",
        "    outputs = keras.ops.take(self.embeddings, inputs, axis=0)\n",
        "    return outputs\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config()\n",
        "    config.update({\n",
        "        \"input_dim\": self.input_dim,\n",
        "        \"output_dim\": self.output_dim,\n",
        "        \"embeddings_initializer\": keras.initializers.serialize(self.embeddings_initializer),\n",
        "        \"mask_zero\": self.mask_zero,\n",
        "    })\n",
        "    return config"
      ],
      "metadata": {
        "id": "smUvdTGHTLqB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MHA**"
      ],
      "metadata": {
        "id": "olBk8oOtmUDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomMHA(keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, weight_initializer=\"glorot_uniform\", causal=False, name=None, **kwargs):\n",
        "    super().__init__(name=name, **kwargs)\n",
        "    self.d_model = d_model\n",
        "    self.num_heads = num_heads\n",
        "    self.d_k = d_model // num_heads\n",
        "    self.causal = causal\n",
        "    self.weight_initializer = keras.initializers.get(weight_initializer)\n",
        "\n",
        "\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.W_qkv = self.add_weight(shape=(self.d_model, 3*self.d_model), initializer=self.weight_initializer, name=\"W_qkv\")\n",
        "    self.b_qkv = self.add_weight(shape=(3*self.d_model,), initializer=\"zeros\", name=\"b_qkv\")\n",
        "    self.W_o = self.add_weight(shape=(self.d_model, self.d_model), initializer=self.weight_initializer, name=\"W_o\")\n",
        "    self.b_o = self.add_weight(shape=(self.d_model,), initializer=\"zeros\", name=\"b_o\")\n",
        "\n",
        "\n",
        "  def call(self, x):\n",
        "    qkv = ops.matmul(x, self.W_qkv) # (N, T, D) @ (D, 3D) => (N, T, 3D)\n",
        "    qkv = ops.add(qkv, self.b_qkv) # gptw had bais term (N, T, 3D)\n",
        "    q, k, v = ops.split(qkv, 3, axis=-1)\n",
        "    # q: (N, T, D)\n",
        "    # v: (N, T, D)\n",
        "    # v: (N, T, D)\n",
        "\n",
        "    new_shape = (ops.shape(q)[0], ops.shape(q)[1], self.num_heads, self.d_k)\n",
        "    q = ops.reshape(q, new_shape) # (N, T, num_heads, d_k)\n",
        "    k = ops.reshape(k, new_shape) # (N, T, num_heads, d_k)\n",
        "    v = ops.reshape(v, new_shape) # (N, T, num_heads, d_k)\n",
        "\n",
        "    q = ops.transpose(q, (0, 2, 1, 3)) # (N, num_heads, T, d_k)\n",
        "    k = ops.transpose(k, (0, 2, 1, 3)) # (N, num_heads, T, d_k)\n",
        "    v = ops.transpose(v, (0, 2, 1, 3)) # (N, num_heads, T, d_k)\n",
        "\n",
        "\n",
        "    dk_float = ops.cast(self.d_k, \"float32\")\n",
        "    scale = ops.sqrt(dk_float)\n",
        "\n",
        "\n",
        "    # (N, num_heads, T, d_k) @ (N, num_heads, d_k, T) => (N, num_heads, T, T)\n",
        "    logits = ops.matmul(q, ops.transpose(k, (0, 1, 3, 2)))\n",
        "    logits = logits / scale # (N, num_heads, T, T)\n",
        "\n",
        "\n",
        "    if self.causal:\n",
        "      seq_len = ops.shape(logits)[-1]\n",
        "      causal_mask = ops.tril(ops.ones((seq_len, seq_len)))\n",
        "      logits = logits + (1.0 - causal_mask) * -1e9\n",
        "      '''\n",
        "      the mask we're adding is:\n",
        "      [\n",
        "        0 -e9 -e9\n",
        "        0 0 -e9\n",
        "        0 0 0\n",
        "      ]\n",
        "      '''\n",
        "\n",
        "    # (N, num_heads, T, T)\n",
        "    weights = ops.softmax(logits, axis=-1)\n",
        "    attn_out = ops.matmul(weights, v)\n",
        "    # (N, num_heads, T, d_v)\n",
        "\n",
        "    attn_out = ops.transpose(attn_out, (0, 2, 1, 3))\n",
        "    out_shape = (ops.shape(attn_out)[0], ops.shape(attn_out)[1], self.num_heads * self.d_k)\n",
        "    attn_out = ops.reshape(attn_out, out_shape)\n",
        "    # (N, T, d_model)\n",
        "\n",
        "    attn_out = ops.matmul(attn_out, self.W_o)\n",
        "    # (N, T, d_model)\n",
        "    attn_out = ops.add(attn_out, self.b_o)\n",
        "    # (N, T, d_model)\n",
        "\n",
        "    return attn_out"
      ],
      "metadata": {
        "id": "BxKeIDah6gie"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FeedForwardNetwork**"
      ],
      "metadata": {
        "id": "kMnKL19LA2wB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedFoward(keras.layers.Layer):\n",
        "  def __init__(self, d_model, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.d_model = d_model\n",
        "\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    # (N, T, d_model\n",
        "    self.ff1 = CustomDense(units=self.d_model * 4, activation=keras.activations.gelu)\n",
        "    # (N, T, 4*d_model)\n",
        "    self.ff2 = CustomDense(units=self.d_model, activation=None)\n",
        "    # (N, T, d_model)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    inputs = self.ff1(inputs)\n",
        "    inputs = self.ff2(inputs)\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "Bx7cZin2A5Kv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decoder Layer**"
      ],
      "metadata": {
        "id": "XT1QE24zHNgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoderLayer(keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, weight_initializer=\"uniform\", causal=True, name=None, **kwargs):\n",
        "    super().__init__(name=name, **kwargs)\n",
        "    self.d_model = d_model\n",
        "    self.num_heads = num_heads\n",
        "    self.causal = causal\n",
        "\n",
        "    self.self_attention = CustomMHA(d_model, num_heads, weight_initializer=weight_initializer, causal=causal)\n",
        "    self.feed_forward = FeedFoward(d_model)\n",
        "\n",
        "    self.layernorm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.layernorm1(x)\n",
        "    attn = self.self_attention(x)\n",
        "    x = ops.add(x, attn)\n",
        "\n",
        "    x = self.layernorm2(x)\n",
        "    ff_output = self.feed_forward(x)\n",
        "    x = ops.add(x, ff_output)\n",
        "\n",
        "\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "7MtUb6HrGLh3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPT2**"
      ],
      "metadata": {
        "id": "hUqae1-tzjl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, vocab_size, max_pos_encoding=1024, name=None, **kwargs):\n",
        "    super().__init__(name=name, **kwargs)\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    self.final_ln = keras.layers.LayerNormalization(epsilon=1e-6, name=\"ln_f\")\n",
        "    self.embedding = CustomEmbedding(input_dim=vocab_size, output_dim=d_model)\n",
        "    self.pos_embedding = self.add_weight(shape=(max_pos_encoding, self.d_model), initializer=\"uniform\", trainable=True, name=\"pos_embedding\")\n",
        "    self.dec_layers = [TransformerDecoderLayer(d_model, num_heads, causal=True, name=f\"decoder_layer_{i}\") for i in range(num_layers)]\n",
        "    self.dropout = keras.layers.Dropout(0.1)\n",
        "\n",
        "\n",
        "  def call(self, x):\n",
        "    seq_len = x.shape[1]\n",
        "    x = self.embedding(x)\n",
        "    pos_embeds = self.pos_embedding[:seq_len, :]\n",
        "    pos_embeds = ops.broadcast_to(pos_embeds, ops.shape(x))\n",
        "    x = ops.add(x, pos_embeds)\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.dec_layers[i](x)\n",
        "\n",
        "    x = self.final_ln(x)\n",
        "    final_logits = ops.matmul(x, ops.transpose(self.embedding.embeddings, (1, 0)))\n",
        "\n",
        "    return final_logits"
      ],
      "metadata": {
        "id": "1KEgmB6YN4Td"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50257\n",
        "d_model = 768\n",
        "num_heads = 12\n",
        "num_layers = 12\n",
        "seq_len = 512\n",
        "batch_size = 1\n",
        "\n",
        "# check whether the output of keras-gpt2 has correct shape.\n",
        "gpt2 = TransformerDecoder(num_layers, d_model, num_heads, vocab_size)\n",
        "sample_input = np.zeros((batch_size, seq_len), dtype='int32')\n",
        "sample_output = gpt2(sample_input)\n",
        "print(sample_output.shape) # (B, T, D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rR4EqU_XOP14",
        "outputId": "66448e1e-f6fa-428e-a9f3-b6f9c7d3af8c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 512, 50257)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check Weight Keys"
      ],
      "metadata": {
        "id": "_hQH-_Cbhblb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for weight in gpt2.weights:\n",
        "  print(weight.name)\n",
        "  count += 1\n",
        "\n",
        "print(f\"{count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0uknXdDVIZQ2",
        "outputId": "ecf076a0-dc19-4c81-9bfd-e0791bb140a8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pos_embedding\n",
            "gamma\n",
            "beta\n",
            "embeddings\n",
            "W_qkv\n",
            "b_qkv\n",
            "W_o\n",
            "b_o\n",
            "kernel\n",
            "bias\n",
            "kernel\n",
            "bias\n",
            "gamma\n",
            "beta\n",
            "gamma\n",
            "beta\n",
            "W_qkv\n",
            "b_qkv\n",
            "W_o\n",
            "b_o\n",
            "kernel\n",
            "bias\n",
            "kernel\n",
            "bias\n",
            "gamma\n",
            "beta\n",
            "gamma\n",
            "beta\n",
            "W_qkv\n",
            "b_qkv\n",
            "W_o\n",
            "b_o\n",
            "kernel\n",
            "bias\n",
            "kernel\n",
            "bias\n",
            "gamma\n",
            "beta\n",
            "gamma\n",
            "beta\n",
            "W_qkv\n",
            "b_qkv\n",
            "W_o\n",
            "b_o\n",
            "kernel\n",
            "bias\n",
            "kernel\n",
            "bias\n",
            "gamma\n",
            "beta\n",
            "gamma\n",
            "beta\n",
            "W_qkv\n",
            "b_qkv\n",
            "W_o\n",
            "b_o\n",
            "kernel\n",
            "bias\n",
            "kernel\n",
            "bias\n",
            "gamma\n",
            "beta\n",
            "gamma\n",
            "beta\n",
            "W_qkv\n",
            "b_qkv\n",
            "W_o\n",
            "b_o\n",
            "kernel\n",
            "bias\n",
            "kernel\n",
            "bias\n",
            "gamma\n",
            "beta\n",
            "gamma\n",
            "beta\n",
            "W_qkv\n",
            "b_qkv\n",
            "W_o\n",
            "b_o\n",
            "kernel\n",
            "bias\n",
            "kernel\n",
            "bias\n",
            "gamma\n",
            "beta\n",
            "gamma\n",
            "beta\n",
            "W_qkv\n",
            "b_qkv\n",
            "W_o\n",
            "b_o\n",
            "kernel\n",
            "bias\n",
            "kernel\n",
            "bias\n",
            "gamma\n",
            "beta\n",
            "gamma\n",
            "beta\n",
            "W_qkv\n",
            "b_qkv\n",
            "W_o\n",
            "b_o\n",
            "kernel\n",
            "bias\n",
            "kernel\n",
            "bias\n",
            "gamma\n",
            "beta\n",
            "gamma\n",
            "beta\n",
            "W_qkv\n",
            "b_qkv\n",
            "W_o\n",
            "b_o\n",
            "kernel\n",
            "bias\n",
            "kernel\n",
            "bias\n",
            "gamma\n",
            "beta\n",
            "gamma\n",
            "beta\n",
            "W_qkv\n",
            "b_qkv\n",
            "W_o\n",
            "b_o\n",
            "kernel\n",
            "bias\n",
            "kernel\n",
            "bias\n",
            "gamma\n",
            "beta\n",
            "gamma\n",
            "beta\n",
            "W_qkv\n",
            "b_qkv\n",
            "W_o\n",
            "b_o\n",
            "kernel\n",
            "bias\n",
            "kernel\n",
            "bias\n",
            "gamma\n",
            "beta\n",
            "gamma\n",
            "beta\n",
            "148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gpt2\"\n",
        "hf_model = GPT2Model.from_pretrained(model_name)\n",
        "hf_model.train() # this is to ensure dropout is also enabled for hf gpt2\n",
        "hf_state_dict = hf_model.state_dict()\n",
        "numpy_state_dict = {k: v.cpu().numpy() for k, v in hf_state_dict.items()}"
      ],
      "metadata": {
        "id": "nfCv6Ax0EQr9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "c59a8862fa6548059e2c139e1e51d9e6",
            "17d7f7d8b0014d71b61da0daccb20c58",
            "9e8dfbe6dc9a4faa92365cbf385b93b4",
            "c6701e6811064783a71c0a986efe7ccf",
            "7ef994692f004aca828c9affaedaa582",
            "4eb13398c0f64ce58c909db8f8063a2d",
            "14847a14e58346f4a00824028b6d07b4",
            "e9783fc3938245e5b36e04e0df58f147",
            "673c1e87b0444f7dbe9272f81870a92d",
            "ccc142ac021d40ccb7ed21314cbbde37",
            "ddc4e6b86a654920a6359c9065ec40eb",
            "49934abd9e314698a5939a4bccfe9881",
            "083d026533bd406a849331aafd6953b3",
            "10cda91616b14ee18ea29ac1d172027a",
            "298828cbfbbf44f4b21af431a8c5155e",
            "b166e859c8534a40a37f0486e0ba6b70",
            "2ec702dba4fc41b2b1f2b5da5148aa32",
            "26bb2ab14ac34d8e8a6fe81a1c949d14",
            "a711f6ed1b5b42a99b244da03e0cd531",
            "fb52338772604c1d8bda2eb37f03b127",
            "b57a2f3a68c54023b0a1e4c8d67781e1",
            "21a47d11fbd84624bef7fefa66fc85e0"
          ]
        },
        "outputId": "07993e0b-901d-4604-aa0e-c72b6529945e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c59a8862fa6548059e2c139e1e51d9e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49934abd9e314698a5939a4bccfe9881"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for key in numpy_state_dict.keys():\n",
        "  count += 1\n",
        "  print(key)\n",
        "\n",
        "print(f\"total num of keys: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Tn2zeYQ3H7BA",
        "outputId": "7f663d00-6f4b-4580-ce29-8267b72d9a2a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wte.weight\n",
            "wpe.weight\n",
            "h.0.ln_1.weight\n",
            "h.0.ln_1.bias\n",
            "h.0.attn.c_attn.weight\n",
            "h.0.attn.c_attn.bias\n",
            "h.0.attn.c_proj.weight\n",
            "h.0.attn.c_proj.bias\n",
            "h.0.ln_2.weight\n",
            "h.0.ln_2.bias\n",
            "h.0.mlp.c_fc.weight\n",
            "h.0.mlp.c_fc.bias\n",
            "h.0.mlp.c_proj.weight\n",
            "h.0.mlp.c_proj.bias\n",
            "h.1.ln_1.weight\n",
            "h.1.ln_1.bias\n",
            "h.1.attn.c_attn.weight\n",
            "h.1.attn.c_attn.bias\n",
            "h.1.attn.c_proj.weight\n",
            "h.1.attn.c_proj.bias\n",
            "h.1.ln_2.weight\n",
            "h.1.ln_2.bias\n",
            "h.1.mlp.c_fc.weight\n",
            "h.1.mlp.c_fc.bias\n",
            "h.1.mlp.c_proj.weight\n",
            "h.1.mlp.c_proj.bias\n",
            "h.2.ln_1.weight\n",
            "h.2.ln_1.bias\n",
            "h.2.attn.c_attn.weight\n",
            "h.2.attn.c_attn.bias\n",
            "h.2.attn.c_proj.weight\n",
            "h.2.attn.c_proj.bias\n",
            "h.2.ln_2.weight\n",
            "h.2.ln_2.bias\n",
            "h.2.mlp.c_fc.weight\n",
            "h.2.mlp.c_fc.bias\n",
            "h.2.mlp.c_proj.weight\n",
            "h.2.mlp.c_proj.bias\n",
            "h.3.ln_1.weight\n",
            "h.3.ln_1.bias\n",
            "h.3.attn.c_attn.weight\n",
            "h.3.attn.c_attn.bias\n",
            "h.3.attn.c_proj.weight\n",
            "h.3.attn.c_proj.bias\n",
            "h.3.ln_2.weight\n",
            "h.3.ln_2.bias\n",
            "h.3.mlp.c_fc.weight\n",
            "h.3.mlp.c_fc.bias\n",
            "h.3.mlp.c_proj.weight\n",
            "h.3.mlp.c_proj.bias\n",
            "h.4.ln_1.weight\n",
            "h.4.ln_1.bias\n",
            "h.4.attn.c_attn.weight\n",
            "h.4.attn.c_attn.bias\n",
            "h.4.attn.c_proj.weight\n",
            "h.4.attn.c_proj.bias\n",
            "h.4.ln_2.weight\n",
            "h.4.ln_2.bias\n",
            "h.4.mlp.c_fc.weight\n",
            "h.4.mlp.c_fc.bias\n",
            "h.4.mlp.c_proj.weight\n",
            "h.4.mlp.c_proj.bias\n",
            "h.5.ln_1.weight\n",
            "h.5.ln_1.bias\n",
            "h.5.attn.c_attn.weight\n",
            "h.5.attn.c_attn.bias\n",
            "h.5.attn.c_proj.weight\n",
            "h.5.attn.c_proj.bias\n",
            "h.5.ln_2.weight\n",
            "h.5.ln_2.bias\n",
            "h.5.mlp.c_fc.weight\n",
            "h.5.mlp.c_fc.bias\n",
            "h.5.mlp.c_proj.weight\n",
            "h.5.mlp.c_proj.bias\n",
            "h.6.ln_1.weight\n",
            "h.6.ln_1.bias\n",
            "h.6.attn.c_attn.weight\n",
            "h.6.attn.c_attn.bias\n",
            "h.6.attn.c_proj.weight\n",
            "h.6.attn.c_proj.bias\n",
            "h.6.ln_2.weight\n",
            "h.6.ln_2.bias\n",
            "h.6.mlp.c_fc.weight\n",
            "h.6.mlp.c_fc.bias\n",
            "h.6.mlp.c_proj.weight\n",
            "h.6.mlp.c_proj.bias\n",
            "h.7.ln_1.weight\n",
            "h.7.ln_1.bias\n",
            "h.7.attn.c_attn.weight\n",
            "h.7.attn.c_attn.bias\n",
            "h.7.attn.c_proj.weight\n",
            "h.7.attn.c_proj.bias\n",
            "h.7.ln_2.weight\n",
            "h.7.ln_2.bias\n",
            "h.7.mlp.c_fc.weight\n",
            "h.7.mlp.c_fc.bias\n",
            "h.7.mlp.c_proj.weight\n",
            "h.7.mlp.c_proj.bias\n",
            "h.8.ln_1.weight\n",
            "h.8.ln_1.bias\n",
            "h.8.attn.c_attn.weight\n",
            "h.8.attn.c_attn.bias\n",
            "h.8.attn.c_proj.weight\n",
            "h.8.attn.c_proj.bias\n",
            "h.8.ln_2.weight\n",
            "h.8.ln_2.bias\n",
            "h.8.mlp.c_fc.weight\n",
            "h.8.mlp.c_fc.bias\n",
            "h.8.mlp.c_proj.weight\n",
            "h.8.mlp.c_proj.bias\n",
            "h.9.ln_1.weight\n",
            "h.9.ln_1.bias\n",
            "h.9.attn.c_attn.weight\n",
            "h.9.attn.c_attn.bias\n",
            "h.9.attn.c_proj.weight\n",
            "h.9.attn.c_proj.bias\n",
            "h.9.ln_2.weight\n",
            "h.9.ln_2.bias\n",
            "h.9.mlp.c_fc.weight\n",
            "h.9.mlp.c_fc.bias\n",
            "h.9.mlp.c_proj.weight\n",
            "h.9.mlp.c_proj.bias\n",
            "h.10.ln_1.weight\n",
            "h.10.ln_1.bias\n",
            "h.10.attn.c_attn.weight\n",
            "h.10.attn.c_attn.bias\n",
            "h.10.attn.c_proj.weight\n",
            "h.10.attn.c_proj.bias\n",
            "h.10.ln_2.weight\n",
            "h.10.ln_2.bias\n",
            "h.10.mlp.c_fc.weight\n",
            "h.10.mlp.c_fc.bias\n",
            "h.10.mlp.c_proj.weight\n",
            "h.10.mlp.c_proj.bias\n",
            "h.11.ln_1.weight\n",
            "h.11.ln_1.bias\n",
            "h.11.attn.c_attn.weight\n",
            "h.11.attn.c_attn.bias\n",
            "h.11.attn.c_proj.weight\n",
            "h.11.attn.c_proj.bias\n",
            "h.11.ln_2.weight\n",
            "h.11.ln_2.bias\n",
            "h.11.mlp.c_fc.weight\n",
            "h.11.mlp.c_fc.bias\n",
            "h.11.mlp.c_proj.weight\n",
            "h.11.mlp.c_proj.bias\n",
            "ln_f.weight\n",
            "ln_f.bias\n",
            "total num of keys: 148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load HuggingFace Weights into Keras GPT-2 Model"
      ],
      "metadata": {
        "id": "aeMsr-s3IrRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_hf_weights_into_keras_model(gpt2_keras, hf_weights):\n",
        "  # embeddings\n",
        "  gpt2_keras.embedding.embeddings.assign(hf_weights[\"wte.weight\"])\n",
        "  gpt2_keras.pos_embedding.assign(hf_weights[\"wpe.weight\"])\n",
        "\n",
        "  # decoder layers\n",
        "  for i, decoder_layer in enumerate(gpt2_keras.dec_layers):\n",
        "    # LN\n",
        "    decoder_layer.layernorm1.gamma.assign(hf_weights[f\"h.{i}.ln_1.weight\"])\n",
        "    decoder_layer.layernorm1.beta.assign(hf_weights[f\"h.{i}.ln_1.bias\"])\n",
        "\n",
        "    decoder_layer.layernorm2.gamma.assign(hf_weights[f\"h.{i}.ln_2.weight\"])\n",
        "    decoder_layer.layernorm2.beta.assign(hf_weights[f\"h.{i}.ln_2.bias\"])\n",
        "\n",
        "    # MHA\n",
        "    decoder_layer.self_attention.W_qkv.assign(hf_weights[f\"h.{i}.attn.c_attn.weight\"])\n",
        "    decoder_layer.self_attention.b_qkv.assign(hf_weights[f\"h.{i}.attn.c_attn.bias\"])\n",
        "    decoder_layer.self_attention.W_o.assign(hf_weights[f\"h.{i}.attn.c_proj.weight\"])\n",
        "    decoder_layer.self_attention.b_o.assign(hf_weights[f\"h.{i}.attn.c_proj.bias\"])\n",
        "\n",
        "    # FFN\n",
        "    decoder_layer.feed_forward.ff1.kernel.assign(hf_weights[f\"h.{i}.mlp.c_fc.weight\"])\n",
        "    decoder_layer.feed_forward.ff1.bias.assign(hf_weights[f\"h.{i}.mlp.c_fc.bias\"])\n",
        "    decoder_layer.feed_forward.ff2.kernel.assign(hf_weights[f\"h.{i}.mlp.c_proj.weight\"])\n",
        "    decoder_layer.feed_forward.ff2.bias.assign(hf_weights[f\"h.{i}.mlp.c_proj.bias\"])\n",
        "\n",
        "  # final layer norm layer\n",
        "  gpt2_keras.final_ln.gamma.assign(hf_weights[\"ln_f.weight\"])\n",
        "  gpt2_keras.final_ln.beta.assign(hf_weights[\"ln_f.bias\"])"
      ],
      "metadata": {
        "id": "k1X2Pw__sNzR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_hf_weights_into_keras_model(gpt2, numpy_state_dict)"
      ],
      "metadata": {
        "id": "Yv8OdtGv12ag"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check Cosine Similarity between HF GPT2 and Keras GPT2 outputs"
      ],
      "metadata": {
        "id": "l-lQ-1Tk13jG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_sim():\n",
        "  tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "  random_input_ids = np.random.randint(0, tokenizer.vocab_size, (1, 10))\n",
        "\n",
        "  torch_input = torch.tensor(random_input_ids)\n",
        "  hf_model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "  hf_output = hf_model(torch_input).logits\n",
        "\n",
        "  tf_input = tf.convert_to_tensor(random_input_ids)\n",
        "  keras_output = gpt2(tf_input).numpy()\n",
        "\n",
        "\n",
        "  hf_output_np = hf_output.detach().cpu().numpy()\n",
        "\n",
        "  sim = dot(hf_output_np.flatten(), keras_output.flatten()) / (norm(hf_output_np.flatten()) * norm(keras_output.flatten()))\n",
        "  return sim"
      ],
      "metadata": {
        "id": "8UdNX1db_bqc"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_sim = 0\n",
        "test_set = 1000\n",
        "for i in range(test_set):\n",
        "  total_sim += check_sim()\n",
        "\n",
        "print(f\"Average cosine similarity between keras gpt2 and hf gpt2 for 1000 random input is {total_sim/test_set}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1jJcknzAJh_",
        "outputId": "11f401b5-01ab-4e40-f29c-e3b15636c370"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average cosine similarity between keras gpt2 and hf gpt2 for 1000 random input is 0.9767636656761169.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5GJDoyfnAJps"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}